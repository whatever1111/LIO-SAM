#!/usr/bin/env python3
"""
Analyze "jump" events in LIO-SAM optimization updates using gps_factor_debug.csv.

Definition (keyframe-level):
  jump ~= |post - pre| at the keyframe update (delta_x/y/z and delta_yaw_deg from gps_factor_debug).

This helps you:
  - detect large corrections (potentially caused by GPS / loop closure / bad data association)
  - attribute each jump to GPS-factor-added / loop-closure / others
  - optionally correlate jumps with holdout error peaks (errors.csv from evaluate_trajectory.py)

Inputs:
  - gps_factor_debug.csv (generated by scripts/evaluate_trajectory.py)
  - optional errors.csv (generated next to errors.png by scripts/evaluate_trajectory.py)

Outputs:
  - jump_events.csv
  - jump_plot.png
"""

from __future__ import annotations

import argparse
import math
import os
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd


def _mad(x: np.ndarray) -> float:
    x = np.asarray(x, dtype=float)
    x = x[np.isfinite(x)]
    if x.size == 0:
        return float("nan")
    med = float(np.median(x))
    return float(np.median(np.abs(x - med)))


def _robust_threshold(x: np.ndarray, k: float, min_thr: float) -> float:
    x = np.asarray(x, dtype=float)
    x = x[np.isfinite(x)]
    if x.size == 0:
        return float(min_thr)
    med = float(np.median(x))
    mad = _mad(x)
    if not np.isfinite(mad) or mad <= 1e-12:
        return float(max(min_thr, med))
    # 1.4826 * MAD ~= sigma for normal distribution
    thr = med + float(k) * 1.4826 * mad
    return float(max(min_thr, thr))


def _wrap_deg(d: float) -> float:
    while d > 180.0:
        d -= 360.0
    while d < -180.0:
        d += 360.0
    return d


def _intervals_from_flag(t: np.ndarray, flag: np.ndarray) -> List[Tuple[float, float]]:
    t = np.asarray(t, dtype=float)
    flag = np.asarray(flag, dtype=int)
    if t.size == 0 or flag.size == 0:
        return []
    intervals: List[Tuple[float, float]] = []
    in_it = False
    s = float(t[0])
    for i in range(flag.size):
        f = bool(flag[i])
        if f and not in_it:
            s = float(t[i])
            in_it = True
        elif (not f) and in_it:
            e = float(t[i])
            if e > s:
                intervals.append((s, e))
            in_it = False
    if in_it:
        intervals.append((float(s), float(t[-1])))
    return intervals


def _load_errors_csv(path: str) -> Optional[pd.DataFrame]:
    if not path:
        return None
    if not os.path.exists(path):
        return None
    df = pd.read_csv(path)
    required = {"t", "t_rel", "error_m"}
    if not required.issubset(set(df.columns)):
        return None
    df = df.sort_values("t").reset_index(drop=True)
    return df


def _match_nearest(t_ref: np.ndarray, t_query: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    t_ref = np.asarray(t_ref, dtype=float)
    t_query = np.asarray(t_query, dtype=float)
    if t_ref.size == 0 or t_query.size == 0:
        return np.zeros((0,), dtype=int), np.zeros((0,), dtype=float)

    idx = np.searchsorted(t_ref, t_query, side="left")
    idx0 = np.clip(idx - 1, 0, t_ref.size - 1)
    idx1 = np.clip(idx, 0, t_ref.size - 1)
    dt0 = np.abs(t_ref[idx0] - t_query)
    dt1 = np.abs(t_ref[idx1] - t_query)
    use1 = dt1 < dt0
    best = np.where(use1, idx1, idx0)
    best_dt = np.where(use1, dt1, dt0)
    return best.astype(int), best_dt.astype(float)


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--gps-debug-csv", required=True, help="gps_factor_debug.csv path")
    ap.add_argument("--errors-csv", default=None, help="Optional errors.csv path (from evaluate_trajectory.py)")
    ap.add_argument("--out-dir", default=None, help="Output dir (default: same dir as gps-debug-csv)")
    ap.add_argument("--pos-min", type=float, default=0.15, help="Minimum position jump threshold (m)")
    ap.add_argument("--yaw-min", type=float, default=5.0, help="Minimum yaw jump threshold (deg)")
    ap.add_argument("--mad-k", type=float, default=6.0, help="Robust threshold = median + k*sigma(MAD)")
    ap.add_argument("--max-events", type=int, default=50, help="Max events to list (largest first)")
    args = ap.parse_args()

    debug_csv = args.gps_debug_csv
    if not os.path.exists(debug_csv):
        raise SystemExit(f"[ERR] file not found: {debug_csv}")

    out_dir = args.out_dir or os.path.dirname(os.path.abspath(debug_csv)) or "."
    os.makedirs(out_dir, exist_ok=True)
    out_csv = os.path.join(out_dir, "jump_events.csv")
    out_png = os.path.join(out_dir, "jump_plot.png")

    df = pd.read_csv(debug_csv)
    for col in ["t", "delta_x", "delta_y", "delta_z", "delta_yaw_deg"]:
        if col not in df.columns:
            raise SystemExit(f"[ERR] missing column '{col}' in {debug_csv}")

    # Ensure numeric
    for c in ["t", "t_rel", "delta_x", "delta_y", "delta_z", "delta_yaw_deg"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    df = df.sort_values("t").reset_index(drop=True)
    if "t_rel" not in df.columns or not np.isfinite(df["t_rel"].to_numpy()).any():
        t0 = float(df["t"].iloc[0])
        df["t_rel"] = df["t"] - t0

    # Derived magnitudes
    df["delta_yaw_deg_wrapped"] = df["delta_yaw_deg"].apply(lambda d: _wrap_deg(float(d)) if np.isfinite(d) else np.nan)
    df["delta_yaw_abs_deg"] = df["delta_yaw_deg_wrapped"].abs()
    df["delta_pos_m"] = np.sqrt(df["delta_x"] ** 2 + df["delta_y"] ** 2 + df["delta_z"] ** 2)

    pos_thr = _robust_threshold(df["delta_pos_m"].to_numpy(), args.mad_k, args.pos_min)
    yaw_thr = _robust_threshold(df["delta_yaw_abs_deg"].to_numpy(), args.mad_k, args.yaw_min)

    is_pos = df["delta_pos_m"] >= pos_thr
    is_yaw = df["delta_yaw_abs_deg"] >= yaw_thr
    is_jump = is_pos | is_yaw

    events = df[is_jump].copy()
    if events.empty:
        print("No jump events found with current thresholds.")
        print(f"  pos_thr={pos_thr:.3f}m yaw_thr={yaw_thr:.3f}deg")
        # Still emit empty CSV for pipeline convenience
        events.to_csv(out_csv, index=False)
        print(f"Saved: {out_csv}")
        return 0

    # Cause attribution (best-effort)
    def _col_bool(name: str) -> np.ndarray:
        if name not in events.columns:
            return np.zeros((events.shape[0],), dtype=bool)
        v = pd.to_numeric(events[name], errors="coerce").fillna(0.0).to_numpy()
        return v > 0.5

    loop = _col_bool("loop_factors_added")
    gps = _col_bool("gps_pos_factor_added") | _col_bool("gps_ori_factor_added")
    deg = _col_bool("gnss_degraded")

    cause = np.where(loop, "loop", np.where(gps, "gps", "other"))
    events["cause"] = cause
    events["event_pos"] = is_pos[is_jump].to_numpy().astype(int)
    events["event_yaw"] = is_yaw[is_jump].to_numpy().astype(int)

    # Correlate with errors.csv if provided
    err_df = _load_errors_csv(args.errors_csv) if args.errors_csv else None
    if err_df is not None and not err_df.empty:
        idx, dt = _match_nearest(err_df["t"].to_numpy(), events["t"].to_numpy())
        events["error_m_nearest"] = err_df["error_m"].to_numpy()[idx]
        events["error_dt_s"] = dt
    else:
        events["error_m_nearest"] = np.nan
        events["error_dt_s"] = np.nan

    # Sort by largest jump first
    events["jump_score"] = np.maximum(events["delta_pos_m"], 0.02 * events["delta_yaw_abs_deg"])  # heuristic
    events = events.sort_values("jump_score", ascending=False).reset_index(drop=True)

    # Save CSV
    events.to_csv(out_csv, index=False)
    print(f"pos_thr={pos_thr:.3f}m yaw_thr={yaw_thr:.3f}deg")
    print(f"events: {len(events)} (saved {out_csv})")

    # Print a small summary
    def _count(mask: np.ndarray) -> int:
        return int(np.sum(mask))

    print("by cause:", {k: int(v) for k, v in events["cause"].value_counts().to_dict().items()})
    if "gnss_degraded" in events.columns:
        try:
            print("by gnss_degraded:", {int(k): int(v) for k, v in events["gnss_degraded"].value_counts().to_dict().items()})
        except Exception:
            pass

    k = max(0, int(args.max_events))
    if k > 0:
        print("")
        print(f"Top-{min(k, len(events))} events:")
        for i in range(min(k, len(events))):
            r = events.iloc[i]
            t = float(r["t"])
            tr = float(r["t_rel"])
            dp = float(r["delta_pos_m"])
            dy = float(r["delta_yaw_deg_wrapped"]) if np.isfinite(r["delta_yaw_deg_wrapped"]) else float("nan")
            c = str(r["cause"])
            g = int(r["gps_pos_factor_added"]) if "gps_pos_factor_added" in r and np.isfinite(r["gps_pos_factor_added"]) else -1
            l = int(r["loop_factors_added"]) if "loop_factors_added" in r and np.isfinite(r["loop_factors_added"]) else -1
            e = float(r["error_m_nearest"]) if np.isfinite(r["error_m_nearest"]) else float("nan")
            print(f"  t_rel={tr:8.3f}s  dp={dp:6.3f}m  dyaw={dy:7.2f}deg  cause={c:5s} gps={g} loop={l} err≈{e:6.3f}m")

    # Plot
    import matplotlib.pyplot as plt

    t_rel = df["t_rel"].to_numpy(dtype=float)
    dp = df["delta_pos_m"].to_numpy(dtype=float)
    dy = df["delta_yaw_abs_deg"].to_numpy(dtype=float)

    intervals = []
    if "gnss_degraded" in df.columns:
        intervals = _intervals_from_flag(t_rel, pd.to_numeric(df["gnss_degraded"], errors="coerce").fillna(0).to_numpy())

    fig, axs = plt.subplots(3 if err_df is not None else 2, 1, figsize=(16, 10), sharex=True)
    if not isinstance(axs, np.ndarray):
        axs = np.asarray([axs])

    def shade(ax):
        for i, (s, e) in enumerate(intervals):
            ax.axvspan(s, e, color="red", alpha=0.12, label="GNSS degraded" if i == 0 else None)

    # 1) Position jump magnitude
    ax0 = axs[0]
    shade(ax0)
    ax0.plot(t_rel, dp, "b-", linewidth=1.0, alpha=0.7, label="|post-pre| position (m)")
    ax0.axhline(pos_thr, color="k", linestyle="--", linewidth=1.0, alpha=0.7, label=f"thr={pos_thr:.3f}m")

    # Mark events by cause
    ev = df[is_jump].copy()
    if not ev.empty:
        # Determine cause on full df slice for plotting consistency
        def _cause_row(row) -> str:
            loop = float(row.get("loop_factors_added", 0.0)) > 0.5
            gps = (float(row.get("gps_pos_factor_added", 0.0)) > 0.5) or (float(row.get("gps_ori_factor_added", 0.0)) > 0.5)
            if loop:
                return "loop"
            if gps:
                return "gps"
            return "other"

        ev["cause"] = ev.apply(_cause_row, axis=1)
        for c, color, marker in [("gps", "g", "o"), ("loop", "m", "s"), ("other", "k", "x")]:
            sub = ev[ev["cause"] == c]
            if sub.empty:
                continue
            ax0.scatter(sub["t_rel"], sub["delta_pos_m"], s=30, c=color, marker=marker, alpha=0.9, label=f"event ({c})")

    ax0.set_ylabel("Δpos (m)")
    ax0.set_title("Keyframe Correction Jumps (from gps_factor_debug)")
    ax0.grid(True, alpha=0.3)
    ax0.legend(ncol=4, fontsize=9, loc="upper right")

    # 2) Yaw jump magnitude
    ax1 = axs[1]
    shade(ax1)
    ax1.plot(t_rel, dy, "c-", linewidth=1.0, alpha=0.8, label="|post-pre| yaw (deg)")
    ax1.axhline(yaw_thr, color="k", linestyle="--", linewidth=1.0, alpha=0.7, label=f"thr={yaw_thr:.2f}deg")
    ax1.set_ylabel("Δyaw (deg)")
    ax1.grid(True, alpha=0.3)
    ax1.legend(fontsize=9, loc="upper right")

    # 3) Error curve (optional)
    if err_df is not None and not err_df.empty and axs.size >= 3:
        ax2 = axs[2]
        shade(ax2)
        ax2.plot(err_df["t_rel"], err_df["error_m"], "r-", linewidth=1.0, alpha=0.75, label="holdout error (m)")
        for t_ev in ev["t_rel"].to_numpy(dtype=float):
            ax2.axvline(float(t_ev), color="k", alpha=0.08)
        ax2.set_ylabel("error (m)")
        ax2.grid(True, alpha=0.3)
        ax2.legend(fontsize=9, loc="upper right")

    axs[-1].set_xlabel("Time (s)")
    plt.tight_layout()
    plt.savefig(out_png, dpi=200)
    print(f"Saved: {out_png}")
    plt.close()

    return 0


if __name__ == "__main__":
    raise SystemExit(main())

